{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) 506\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_boston\n",
    "#导出数据，X为特征，y为房价\n",
    "data = load_boston()\n",
    "X,y = data['data'], data['target']\n",
    "print(X.shape,len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a1db859fd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#以X中的一个特征和y作图\n",
    "def price(rm,k,b):\n",
    "    return rm * k + b\n",
    "#选择X的第五个特征，房间数量\n",
    "X_rm = X[:,5]\n",
    "k = random.randint(-100,100)\n",
    "b = random.randint(-100,100)\n",
    "price_by_random = [price(r,k,b) for r in X_rm]\n",
    "\n",
    "plt.scatter(X_rm,y,label=\"real price\")\n",
    "plt.scatter(X_rm,price_by_random,label=\"random price\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    " $$ loss = \\frac{1}{n} \\sum{(y_i - \\hat{y_i})}^2$$\n",
    " $$ loss = \\frac{1}{n} \\sum{(y_i - (kx_i + b_i))}^2 $$\n",
    " \n",
    " $$ \\frac{\\partial{loss}}{\\partial{k}} = -\\frac{2}{n}\\sum(y_i - (kx_i + b_i))x_i$$\n",
    " \n",
    " $$ \\frac{\\partial{loss}}{\\partial{k}} = -\\frac{2}{n}\\sum(y_i - \\hat{y_i})x_i$$\n",
    " \n",
    " $$ \\frac{\\partial{loss}}{\\partial{b}} = -\\frac{2}{n}\\sum(y_i - \\hat{y_i})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, y_hat): # to evaluate the performance \n",
    "    return sum((y_i - y_hat_i)**2 for y_i, y_hat_i in zip(list(y), list(y_hat))) / len(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_k(x, y, y_hat):\n",
    "    n = len(y)\n",
    "\n",
    "    gradient = 0\n",
    "    \n",
    "    for x_i, y_i, y_hat_i in zip(list(x), list(y), list(y_hat)):\n",
    "        gradient += (y_i - y_hat_i) * x_i\n",
    "    \n",
    "    return -2 / n * gradient\n",
    "\n",
    "\n",
    "def partial_b(x, y, y_hat):\n",
    "    n = len(y)\n",
    "\n",
    "    gradient = 0\n",
    "    \n",
    "    for y_i, y_hat_i in zip(list(y), list(y_hat)):\n",
    "        gradient += (y_i - y_hat_i)\n",
    "    \n",
    "    return -2 / n * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 老师的方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When time is : 0, get best_k: -99.01598446396869 best_b: 47.43571900370944, and the loss is: 362661.4735492204\n",
      "When time is : 50, get best_k: -67.67239868830767 best_b: 52.351174524173274, and the loss is: 159350.48807884977\n",
      "When time is : 100, get best_k: -46.90097999701338 best_b: 55.60463321393186, and the loss is: 70067.21410028754\n",
      "When time is : 150, get best_k: -33.13553683251437 best_b: 57.7567184651388, and the loss is: 30858.782915737076\n",
      "When time is : 200, get best_k: -24.012821403449948 best_b: 59.178944811350746, and the loss is: 13640.531559218083\n",
      "When time is : 250, get best_k: -17.96675403260124 best_b: 60.11750791718839, and the loss is: 6079.1853868689695\n",
      "When time is : 300, get best_k: -13.959523296058007 best_b: 60.73555699969747, and the loss is: 2758.6329920767594\n",
      "When time is : 350, get best_k: -11.303391164094853 best_b: 61.141207963595384, and the loss is: 1300.4093186488112\n",
      "When time is : 400, get best_k: -9.542606633556018 best_b: 61.40610717692105, and the loss is: 660.0203377834762\n",
      "When time is : 450, get best_k: -8.375152122307044 best_b: 61.57773333454856, and the loss is: 378.7804054082871\n",
      "When time is : 500, get best_k: -7.60088628279608 best_b: 61.687549670795015, and the loss is: 255.2594374086705\n",
      "When time is : 550, get best_k: -7.087179224015833 best_b: 61.756406276746745, and the loss is: 201.00016613091017\n",
      "When time is : 600, get best_k: -6.746139622137521 best_b: 61.798120113919126, and the loss is: 177.15691350632179\n",
      "When time is : 650, get best_k: -6.519523556834405 best_b: 61.821847421693924, and the loss is: 166.67074537736983\n",
      "When time is : 700, get best_k: -6.3687338821367625 best_b: 61.83365586692104, and the loss is: 162.05029464534917\n",
      "When time is : 750, get best_k: -6.268192998377107 best_b: 61.83756637776665, and the loss is: 160.00575548195448\n",
      "When time is : 800, get best_k: -6.20095111332521 best_b: 61.836243547327506, and the loss is: 159.09242196781048\n",
      "When time is : 850, get best_k: -6.15577591978809 best_b: 61.83145315106675, and the loss is: 158.67585690386662\n",
      "When time is : 900, get best_k: -6.125223979922096 best_b: 61.824365334977315, and the loss is: 158.47744956743824\n",
      "When time is : 950, get best_k: -6.104362668041869 best_b: 61.8157555326519, and the loss is: 158.3748491013732\n",
      "When time is : 1000, get best_k: -6.0899232262582155 best_b: 61.80613760923043, and the loss is: 158.31432558371588\n",
      "When time is : 1050, get best_k: -6.07973951044536 best_b: 61.79585209337928, and the loss is: 158.27228371941197\n",
      "When time is : 1100, get best_k: -6.072376057793732 best_b: 61.78512464695762, and the loss is: 158.23836172204227\n",
      "When time is : 1150, get best_k: -6.066881614201805 best_b: 61.77410481176094, and the loss is: 158.2080092509819\n",
      "When time is : 1200, get best_k: -6.062625801533725 best_b: 61.76289168625623, and the loss is: 158.17922804028\n",
      "When time is : 1250, get best_k: -6.05919088009579 best_b: 61.751550941069375, and the loss is: 158.15114055802846\n",
      "When time is : 1300, get best_k: -6.056300021673845 best_b: 61.74012609482729, and the loss is: 158.12336143848066\n",
      "When time is : 1350, get best_k: -6.053769777429875 best_b: 61.72864598644563, and the loss is: 158.09572144881759\n",
      "When time is : 1400, get best_k: -6.051478579274805 best_b: 61.71712972687259, and the loss is: 158.06814627018727\n",
      "When time is : 1450, get best_k: -6.049345866323146 best_b: 61.7055899805161, and the loss is: 158.04060326485168\n",
      "When time is : 1500, get best_k: -6.047318252388747 best_b: 61.69403513978358, and the loss is: 158.01307809917722\n",
      "When time is : 1550, get best_k: -6.04536035944545 best_b: 61.68247076610845, and the loss is: 157.98556447771054\n",
      "When time is : 1600, get best_k: -6.043448743134616 best_b: 61.6709005448911, and the loss is: 157.95805963493478\n",
      "When time is : 1650, get best_k: -6.041567867313687 best_b: 61.6593269183203, and the loss is: 157.93056235549113\n",
      "When time is : 1700, get best_k: -6.039707436465542 best_b: 61.647751504731964, and the loss is: 157.90307210476882\n",
      "When time is : 1750, get best_k: -6.0378606279365545 best_b: 61.63617537651025, and the loss is: 157.87558864710283\n",
      "When time is : 1800, get best_k: -6.036022920474147 best_b: 61.62459924424739, and the loss is: 157.8481118781117\n",
      "When time is : 1850, get best_k: -6.034191317920755 best_b: 61.61302357878311, and the loss is: 157.8206417510651\n",
      "When time is : 1900, get best_k: -6.032363834770482 best_b: 61.601448692077376, and the loss is: 157.79317824455092\n",
      "When time is : 1950, get best_k: -6.0305391552571885 best_b: 61.589874790803904, and the loss is: 157.76572134827578\n"
     ]
    }
   ],
   "source": [
    "trying_times = 2000\n",
    "min_loss = float('inf') \n",
    "\n",
    "current_k = random.random() * 200 - 100\n",
    "current_b = random.random() * 200 - 100\n",
    "\n",
    "learning_rate = 1e-04\n",
    "update_time = 0\n",
    "\n",
    "for i in range(trying_times):\n",
    "    price_by_k_and_b = [price(r, current_k, current_b) for r in X_rm]\n",
    "    current_loss = loss(y, price_by_k_and_b)\n",
    "\n",
    "    if current_loss < min_loss: # performance became better\n",
    "        min_loss = current_loss\n",
    "        \n",
    "        if i % 50 == 0: \n",
    "            print('When time is : {}, get best_k: {} best_b: {}, and the loss is: {}'.\n",
    "                  format(i, current_k, current_b, min_loss))\n",
    "    #利用公式求出k/b的导数\n",
    "    k_gradient = partial_k(X_rm, y, price_by_k_and_b)\n",
    "    b_gradient = partial_b(X_rm, y, price_by_k_and_b)\n",
    "    #更新参数\n",
    "    current_k = current_k + (-1 * k_gradient) * learning_rate\n",
    "    current_b = current_b + (-1 * b_gradient) * learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 我的方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In loop: 0,k: 25.35870000015545, b: -36.15568310968336, loss: 10310.606836230341\n",
      "In loop: 50,k: 15.275981126840076, b: -37.7395232220877, loss: 1339.1296159493118\n",
      "In loop: 100,k: 11.694473804693226, b: -38.30134028452595, loss: 207.22131127944934\n",
      "In loop: 150,k: 10.422200410223173, b: -38.500134431316454, loss: 64.41125153288957\n",
      "In loop: 200,k: 9.970168203410637, b: -38.56998286980798, loss: 46.393173214781534\n",
      "In loop: 250,k: 9.809486150239852, b: -38.59402995175025, loss: 44.11977825945264\n",
      "In loop: 300,k: 9.752291866728344, b: -38.60180859619924, loss: 43.83284956528463\n",
      "In loop: 350,k: 9.731856531532081, b: -38.6038089120549, loss: 43.7965482699083\n",
      "In loop: 400,k: 9.72447803087568, b: -38.60375699165551, loss: 43.79186804900921\n",
      "In loop: 450,k: 9.721737360997736, b: -38.602976344964596, loss: 43.79117743794831\n",
      "In loop: 500,k: 9.720644087155973, b: -38.601937083374736, loss: 43.7909902458706\n",
      "In loop: 550,k: 9.720136005286806, b: -38.60080619064031, loss: 43.790866629006985\n",
      "In loop: 600,k: 9.719835819916232, b: -38.599642979413225, loss: 43.79075109336434\n",
      "In loop: 650,k: 9.719609515475138, b: -38.598468517511, loss: 43.79063663737221\n",
      "In loop: 700,k: 9.719409489549399, b: -38.597290288165105, loss: 43.790522377624406\n",
      "In loop: 750,k: 9.719218833724737, b: -38.59611094935472, loss: 43.79040820262765\n",
      "In loop: 800,k: 9.719031542112344, b: -38.594931445126704, loss: 43.79029409827919\n",
      "In loop: 850,k: 9.71884548140645, b: -38.59375211073832, loss: 43.79018006276359\n",
      "In loop: 900,k: 9.718659893844881, b: -38.59257306520444, loss: 43.79006609581586\n",
      "In loop: 950,k: 9.718474510259297, b: -38.59139435073055, loss: 43.78995219736655\n",
      "In loop: 1000,k: 9.718289235030158, b: -38.59021598223933, loss: 43.78983836737094\n",
      "In loop: 1050,k: 9.718104034182566, b: -38.58903796496273, loss: 43.78972460578739\n",
      "In loop: 1100,k: 9.717918895637832, b: -38.58786030069051, loss: 43.78961091257483\n",
      "In loop: 1150,k: 9.717733815094816, b: -38.58668298998979, loss: 43.78949728769202\n",
      "In loop: 1200,k: 9.717548791014964, b: -38.58550603299344, loss: 43.789383731097985\n",
      "In loop: 1250,k: 9.717363822841003, b: -38.58432942968008, loss: 43.78927024275168\n",
      "In loop: 1300,k: 9.717178910364225, b: -38.58315317997361, loss: 43.789156822612114\n",
      "In loop: 1350,k: 9.716994053499713, b: -38.58197728377844, loss: 43.789043470638184\n",
      "In loop: 1400,k: 9.716809252206533, b: -38.580801740992136, loss: 43.788930186789\n",
      "In loop: 1450,k: 9.716624506459397, b: -38.57962655150982, loss: 43.788816971023614\n",
      "In loop: 1500,k: 9.716439816238545, b: -38.57845171522582, loss: 43.78870382330113\n",
      "In loop: 1550,k: 9.716255181526222, b: -38.57727723203414, loss: 43.788590743580656\n",
      "In loop: 1600,k: 9.716070602305335, b: -38.576103101828735, loss: 43.78847773182127\n",
      "In loop: 1650,k: 9.715886078559079, b: -38.57492932450351, loss: 43.78836478798213\n",
      "In loop: 1700,k: 9.715701610270742, b: -38.573755899952424, loss: 43.7882519120225\n",
      "In loop: 1750,k: 9.715517197423631, b: -38.5725828280695, loss: 43.788139103901386\n",
      "In loop: 1800,k: 9.715332840001079, b: -38.57141010874869, loss: 43.788026363578325\n",
      "In loop: 1850,k: 9.715148537986423, b: -38.57023774188403, loss: 43.78791369101233\n",
      "In loop: 1900,k: 9.714964291363012, b: -38.569065727369626, loss: 43.78780108616272\n",
      "In loop: 1950,k: 9.714780100114197, b: -38.56789406509959, loss: 43.78768854898885\n"
     ]
    }
   ],
   "source": [
    "trying_times = 2000\n",
    "min_loss = float('inf')\n",
    "best_k,best_b = random.random() * 200 - 100,random.random() * 200 - 100\n",
    "n = 0\n",
    "alpha = 0.0005\n",
    "\n",
    "\n",
    "\n",
    "while n < trying_times:\n",
    "    price_by_random = [price(r,best_k,best_b) for r in X_rm]\n",
    "    gradient_loss = loss(y,price_by_random)\n",
    "    if gradient_loss < min_loss:\n",
    "        min_loss = gradient_loss\n",
    "        if n % 50 ==0:\n",
    "            print(\"In loop: {},k: {}, b: {}, loss: {}\".format(n,best_k,best_b,gradient_loss))\n",
    "    n += 1\n",
    "    #diff_k和diff_b是参数k和b的偏导数的求和部分\n",
    "    diff_k,diff_b =0,0\n",
    "    for i in range(len(X_rm)):\n",
    "        #y = x0*k + x1*b, 其中x1=1\n",
    "        diff_k += (best_k * X_rm[i-1] + best_b - y[i-1]) * X_rm[i-1]\n",
    "        diff_b += (best_k * X_rm[i-1] + best_b - y[i-1]) * 1\n",
    "    #梯度下降\n",
    "    best_k -= alpha * (diff_k / len(X_rm))\n",
    "    best_b -= alpha * (diff_b / len(X_rm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降的速度很大的依赖于学习率的大小，如果学习率太小则速度会很慢。例如在alpha=0.0001时，几乎需要迭代1000次才能使得loss降为100左右；如果把alpha设置为0.0005，则在迭代不到200次的时候就达到了loss值100以下。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
