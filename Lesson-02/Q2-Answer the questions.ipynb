{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Why do we need machine learning methods instead of creating a complicated formula?¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 因为机器学习的速度更快，而且从数学上可以证明，机器学习的方法能够使得我们的目标函数最大化或者最小化，从而达到我们想要的目标，或者是求得理想的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Wha't's the disadvantages of the 1st Random Choosen methods in our course?¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 随机选择参数的初始误差太大，而且并不能保证每一次随机选择都能够让误差，即loss变小，这对我们来说是一种资源的浪费。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Is the 2nd method supervised direction better than 1st one? What's the disadvantages of the 2nd supversied directin method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 从loss减少的角度来看，第二种监督方向的方法确实比第一种强，因为它明确了一个对的方向，可以使得loss能持续地减少。但它也有几个不足之处，一个是步长(scalar)不好确定，还有一个是初始化的参数对迭代次数有很严重的影响。若初始化的参数设置得较好，则经过较少的迭代便能使得loss达到最优，反之则需要迭代很久。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Why do we use Derivative / Gredient to fit a target function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 因为数学上可以证明，偏导数或者说梯度，是参数在某一时间段上变化最大的方向。要使得目标函数尽可能快地达到全局最优或者是局部最优，就可以让参数沿着参数的梯度去变化，从而达到最优。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. In the words 'Gredient Descent', what's the Gredient and what's the Descent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对于梯度下降这个词而言，梯度就是目标函数中参数的偏导数，下降就是损失函数基于参数沿着梯度的方向进行变化，使得loss值不停减少的过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What's the advantages of the 3rd gradient descent method compared to the previous methods?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 梯度下降总是能够确定一个对的方向去使得loss不停减少，但不足在于，学习率和初始化的参数。学习率过大会使得loss值直接跳过最优点，过小则需要很多次迭代。初始化参数的问题和之前提到的一样，好则快，差则慢。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Using the simple words to describe: What's the machine leanring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 机器学习就是给定一个任务，基于经验去不停地提高表现。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
